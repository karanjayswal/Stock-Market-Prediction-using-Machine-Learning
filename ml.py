# -*- coding: utf-8 -*-
"""ML_Lab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DW8qEiUpgrkS407lFvj6yvZ76OX-USth

# Predict the Stock Market
"""

import pandas as pd

import yfinance as yf

# pip install yfinance

from plotly import graph_objs as go
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

from googlesearch import search
from yfinance import *

def name_convert(self):
    searchval = 'yahoo finance '+self
    link = []
    searchs = search(searchval, tld='es', lang='es', stop=5)
    for url in searchs:
        link.append(url)
    link = str(link[0])
    link=link.split("/")
    if link[-1]=='':
        ticker=link[-2]
    else:
        x=link[-1].split('=')
        ticker=x[-1]
    return ticker

company_name=input("Enter a company name: ")
company=name_convert(company_name)
x = company.split(".")
# print(x)
try:
    if(x[1]=='BO'):
        company = x[0]+'.'+'NS'
        print(company)
except:
    print(company)
# print(company)
cur = yf.Ticker(company)
details = cur.info
currency = details['currency']
try:
    desc = details['longBusinessSummary']
except:
    try:
        desc = details['description']
    except:
        desc=' '

if desc!=' ':
    print("Description: ")
    print(desc)
print("Currency: ",currency)

"""## Dataframe download"""

dataframe = yf.download(company, period = '270d', interval = '1d')

print(currency)
if currency!="INR":
    print("YES")

if currency!="INR":
    import requests
    url = 'https://v6.exchangerate-api.com/v6/d81efaa7bb08ee79f61d3170/latest/'+currency
    response = requests.get(url)
    currency_rate = response.json()
    rate = currency_rate["conversion_rates"]['INR']
    print(rate)
else:
    rate = 1

dataframe.tail()

# dataframe1.tail()

dataframe['Open'] = dataframe['Open'].apply(lambda x: x*rate)
dataframe['High'] = dataframe['High'].apply(lambda x: x*rate)
dataframe['Low'] = dataframe['Low'].apply(lambda x: x*rate)
dataframe['Close'] = dataframe['Close'].apply(lambda x: x*rate)
dataframe['Adj Close'] = dataframe['Adj Close'].apply(lambda x: x*rate)

dataframe = dataframe.drop(['Adj Close'], axis=1)

dataframe.info()

# dataframe = dataframe.seti

dataframe.tail()

dataframe = dataframe.reset_index()

dataframe.head()

dataframe = dataframe.round(2)

dataframe.head()

dataframe.info()

dataframe.head()

# dataframe1.head()

print("Dataframe Shape: ", dataframe. shape)
print("Null Value Present: ", dataframe.isnull().values.any())
print("Number of 0 volumes:",(dataframe['Volume'] == 0).sum())

dataframe = dataframe.drop(dataframe[dataframe['Volume'] == 0].index)
dataframe

#declare figure
fig = go.Figure()
df = dataframe
#Set up traces
fig.add_trace(go.Candlestick(x=df.index,
                open=df['Open'],
                high=df['High'],
                low=df['Low'],
                close=df['Close'], name = 'market data'))

# Add titles
fig.update_layout(
    title=company_name+' price',
    yaxis_title='Stock Price (Rs. per Shares)')

# X-Axes
fig.update_xaxes(
    rangeslider_visible=True,
    rangeselector=dict(
        buttons=list([
            dict(count=1, label="30m", step="minute", stepmode="backward"),
            dict(count=6, label="90m", step="minute", stepmode="backward"),
            dict(count=1, label="HTD", step="hour", stepmode="todate"),
            dict(step="all")
        ])
    )
)

#Show
fig.show()

"""## Data Modeling

### Data Splitting
"""

mData = dataframe.copy(deep=True)

mData

from sklearn.preprocessing import MinMaxScaler

# MinMax Scalar
mean = mData["Close"].mean()
max_value = mData["Close"].max()
min_value = mData["Close"].min()
rang = max_value - min_value
print(rang)
if(rang>800):
    mData['Close'] = dataframe['Close'].apply(lambda x: abs((x-mean)/rang))

mData

mData.shape

plt.figure(figsize=(16,8))
plt.title(company_name)
plt.xlabel("Days")
plt.ylabel("Close Price (Rs)")
plt.plot(mData['Close'])

cData = mData[['Close']]
cData.head()
# len(cData)

import math
future_days = math.ceil(0.2*len(cData))
cData['Prediction'] = cData[['Close']].shift(-future_days)
cData.tail()

import numpy as np
X = np.array(cData.drop(['Prediction'],1))[:-future_days]
# X

Y = np.array(cData['Prediction'])[:-future_days]

# Y

from sklearn.model_selection import train_test_split
x_train,y_test,y_train,y_test = train_test_split(X,Y,test_size=0.25)

# x_train

x_future = cData.drop(['Prediction'],1)[:-future_days]
x_future = x_future.tail(future_days)
x_future = np.array(x_future)

cData

"""# Modeling

**Importing of libaries**
"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.linear_model import BayesianRidge
import math

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras import Sequential
from keras.layers import Dense,LSTM

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_absolute_percentage_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

"""**Fitting of models**"""

tree = DecisionTreeRegressor().fit(x_train,y_train)
rf = RandomForestRegressor(n_estimators = 1000, random_state = 42).fit(x_train,y_train)
lr = LinearRegression().fit(x_train,y_train)
svr_reg = SVR(kernel='rbf')
svr_reg.fit(x_train,y_train)
lasso_reg = Lasso(normalize=True)
lasso_reg.fit(x_train,y_train)
knn = KNeighborsRegressor(n_neighbors=8)
KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
          metric_params=None, n_jobs=1, n_neighbors=8, p=2,
          weights='uniform') 
knn.fit(x_train,y_train)
bay_ridge = BayesianRidge()
BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,
       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,
       normalize=False, tol=0.001, verbose=False) 
bay_ridge.fit(x_train, y_train)
gbr = GradientBoostingRegressor(n_estimators=600, 
    max_depth=5, 
    learning_rate=0.01, 
    min_samples_split=3)
gbr.fit(x_train, y_train)
ada_reg = AdaBoostRegressor(n_estimators=100)
AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
         n_estimators=100, random_state=None) 

ada_reg.fit(x_train, y_train)

"""As regression problems use supervised data, we know Y_actual, and predictions will be considered accurate when Y_predicted is exactly equal to Y_actual. 

But, in regression problems, we have a continuous target variable. 

So, if we start evaluating our model on accuracy parameters, we will end up overfitting our model.

1. Mean Absolute Error (MAE)
2. Mean Absolute Percentage Error (MAPE)
3. Mean Squared Error (MSE)
4. R-Squared (R²)

## 1. Linear Regression
"""

# x_future

lr_prediction = lr.predict(x_future)

predictions = lr_prediction
valid = cData[X.shape[0]:]
valid['Predictions'] = predictions
plt.figure(figsize=(16,8))
plt.title("Linear Regression Model")
plt.xlabel("Days")
plt.ylabel("Close Price (Rs.)")
plt.plot(cData['Close'])
plt.plot(valid[['Close','Predictions']])
plt.legend(['Original','Value','Prediction'])
mae_lr = mean_absolute_error(valid['Close'], predictions)
mape_lr = mean_absolute_percentage_error(valid['Close'], predictions)
mse_lr = mean_squared_error(valid['Close'], predictions)
r2_lr =  r2_score(valid['Close'], predictions)
print("R_Squared = ",r2_lr)
print("MSE = ",mse_lr)
print("MAPE = ",mape_lr)
print("MAE = ",mae_lr)
plt.show()

"""## 2. Decision Tree"""

tree_prediction = tree.predict(x_future)
# tree_prediction

predictions = tree_prediction

valid = cData[X.shape[0]:]
valid['Predictions'] = predictions
plt.figure(figsize=(16,8))
plt.title("Tree Predicition Model")
plt.xlabel("Days")
plt.ylabel("Close Price (Rs.)")
plt.plot(cData['Close'])
plt.plot(valid[['Close','Predictions']])
plt.legend(['Original','Value','Prediction'])
mae_tree = mean_absolute_error(valid['Close'], predictions)
mape_tree = mean_absolute_percentage_error(valid['Close'], predictions)
mse_tree = mean_squared_error(valid['Close'], predictions)
r2_tree =  r2_score(valid['Close'], predictions)
print("R_Squared = ",r2_tree)
print("MSE = ",mse_tree)
print("MAPE = ",mape_tree)
print("MAE = ",mae_tree)
plt.show()

"""## 3. Random Forest"""





rf_prediction = rf.predict(x_future)
predictions = rf_prediction

valid = cData[X.shape[0]:]
valid['Predictions'] = predictions
plt.figure(figsize=(16,8))
plt.title("Random Forest Model")
plt.xlabel("Days")
plt.ylabel("Close Price (Rs.)")
plt.plot(cData['Close'])
plt.plot(valid[['Close','Predictions']])
plt.legend(['Original','Value','Prediction'])
mae_rf = mean_absolute_error(valid['Close'], predictions)
mape_rf = mean_absolute_percentage_error(valid['Close'], predictions)
mse_rf = mean_squared_error(valid['Close'], predictions)
r2_rf =  r2_score(valid['Close'], predictions)
print("R_Squared = ",r2_rf)
print("MSE = ",mse_rf)
print("MAPE = ",mape_rf)
print("MAE = ",mae_rf)
plt.show()

"""## 4.SVR"""

svr_pred = svr_reg.predict(x_future)
predictions = svr_pred

valid = cData[X.shape[0]:]
valid['Predictions'] = predictions
plt.figure(figsize=(16,8))
plt.title("SVR Regression Model")
plt.xlabel("Days")
plt.ylabel("Close Price (Rs.)")
plt.plot(cData['Close'])
plt.plot(valid[['Close','Predictions']])
plt.legend(['Original','Value','Prediction'])
mae_svr = mean_absolute_error(valid['Close'], predictions)
mape_svr = mean_absolute_percentage_error(valid['Close'], predictions)
mse_svr = mean_squared_error(valid['Close'], predictions)
r2_svr =  r2_score(valid['Close'], predictions)
print("R_Squared = ",r2_svr)
print("MSE = ",mse_svr)
print("MAPE = ",mape_svr)
print("MAE = ",mae_svr)
plt.show()

"""## 5.LSTM"""

import math
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras import Sequential
from keras.layers import Dense,LSTM
df = mData.copy(deep=True)
data = df.filter(['Close'])
dataset = data.values
training_data_len = math.ceil(len(dataset)*0.8)
# training_data_len
#Scale the data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)
# scaled_data

train_data = scaled_data[0:training_data_len,:]
#Spliting 
x_train = []
y_train = []
for i in range(60,len(train_data)):
    x_train.append(train_data[i-60:i,0])
    y_train.append(train_data[i,0])
#     if i<=61:
#         print(x_train)
#         print(y_train)
#         print()

#convert the x_train,y_train to numpy array
x_train,y_train = np.array(x_train),np.array(y_train)
# Reshape
x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))
# x_train.shape

#Build the LSTM model
model = Sequential()
model.add(LSTM(50,return_sequences=True,input_shape=(x_train.shape[1],1)))
model.add(LSTM(50,return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam',loss='mean_squared_error')

#Train the model
model.fit(x_train,y_train,batch_size=1,epochs=1)

# Create the testing dataset 
test_data = scaled_data[training_data_len-60:,:]

#Create the data sets x_test,y_test
x_test=[]
y_test = dataset[training_data_len,:]
for i in range(60,len(test_data)):
    x_test.append(test_data[i-60:i,0])
    

# Convert the data to numpy
x_test = np.array(x_test)
x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))

predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)
train = data[:training_data_len]
valid = data[training_data_len:]
valid['Predictions'] = predictions
plt.figure(figsize=(16,8))
plt.title("LSTM Model")
plt.xlabel('Date',fontsize=18)
plt.ylabel('Close Price (Rs.)')
plt.plot(train['Close'])
plt.plot(valid[['Close','Predictions']])
plt.legend(['Original','Value','Prediction'])
mae_lstm = mean_absolute_error(valid['Close'], predictions)
mape_lstm = mean_absolute_percentage_error(valid['Close'], predictions)
mse_lstm = mean_squared_error(valid['Close'], predictions)
r2_lstm =  r2_score(valid['Close'], predictions)
print("R_Squared = ",r2_lstm)
print("MSE = ",mse_lstm)
print("MAPE = ",mape_lstm)
print("MAE = ",mae_lstm)
plt.show()

"""## 6. Lasso """

lasso_prediction =lasso_reg.predict(x_future)
predictions = lasso_prediction

valid = cData[X.shape[0]:]
valid['Predictions'] = predictions
plt.figure(figsize=(16,8))
plt.title("Linear Regression Model")
plt.xlabel("Days")
plt.ylabel("Close Price (Rs.)")
plt.plot(cData['Close'])
plt.plot(valid[['Close','Predictions']])
plt.legend(['Original','Value','Prediction'])
mae_lasso = mean_absolute_error(valid['Close'], predictions)
mape_lasso = mean_absolute_percentage_error(valid['Close'], predictions)
mse_lasso = mean_squared_error(valid['Close'], predictions)
r2_lasso =  r2_score(valid['Close'], predictions)
print("R_Squared = ",r2_lasso)
print("MSE = ",mse_lasso)
print("MAPE = ",mape_lasso)
print("MAE = ",mae_lasso)
plt.show()
# negative R² can be,
# 1. Model is not learning the trend that is present in the train data.
# 2. Too little data has been used to evaluate the model compared to train data.
# 3. Too many outliers are present in the dataset.

"""## 7. KNN"""

knn_pred = knn.predict(x_future)
predictions = knn_pred

valid = cData[X.shape[0]:]
valid['Predictions'] = predictions
plt.figure(figsize=(16,8))
plt.title("KNN Regression Model")
plt.xlabel("Days")
plt.ylabel("Close Price (Rs.)")
plt.plot(cData['Close'])
plt.plot(valid[['Close','Predictions']])
plt.legend(['Original','Value','Prediction'])
mae_knn = mean_absolute_error(valid['Close'], predictions)
mape_knn = mean_absolute_percentage_error(valid['Close'], predictions)
mse_knn = mean_squared_error(valid['Close'], predictions)
r2_knn =  r2_score(valid['Close'], predictions)
print("R_Squared = ",r2_knn)
print("MSE = ",mse_knn)
print("MAPE = ",mape_knn)
print("MAE = ",mae_knn)
plt.show()

"""## 8. Bayesian Ridge"""

bar_pred = bay_ridge.predict(x_future)
predictions = bar_pred

valid = cData[X.shape[0]:]
valid['Predictions'] = predictions
plt.figure(figsize=(16,8))
plt.title("Bayesian Regression Model")
plt.xlabel("Days")
plt.ylabel("Close Price (Rs.)")
plt.plot(cData['Close'])
plt.plot(valid[['Close','Predictions']])
plt.legend(['Original','Value','Prediction'])
mae_bar = mean_absolute_error(valid['Close'], predictions)
mape_bar = mean_absolute_percentage_error(valid['Close'], predictions)
mse_bar = mean_squared_error(valid['Close'], predictions)
r2_bar =  r2_score(valid['Close'], predictions)
print("R_Squared = ",r2_bar)
print("MSE = ",mse_bar)
print("MAPE = ",mape_bar)
print("MAE = ",mae_bar)
plt.show()

"""## 9. Gradient Boosting"""

gbr_pred = gbr.predict(x_future)
predictions = gbr_pred

valid = cData[X.shape[0]:]
valid['Predictions'] = predictions
plt.figure(figsize=(16,8))
plt.title("Gradient Boosting Regression Model")
plt.xlabel("Days")
plt.ylabel("Close Price (Rs.)")
plt.plot(cData['Close'])
plt.plot(valid[['Close','Predictions']])
plt.legend(['Original','Value','Prediction'])
mae_gbr = mean_absolute_error(valid['Close'], predictions)
mape_gbr = mean_absolute_percentage_error(valid['Close'], predictions)
mse_gbr = mean_squared_error(valid['Close'], predictions)
r2_gbr =  r2_score(valid['Close'], predictions)
print("R_Squared = ",r2_gbr)
print("MSE = ",mse_gbr)
print("MAPE = ",mape_gbr)
print("MAE = ",mae_gbr)
plt.show()

"""## 10. AdaBoost"""

ada_pred = ada_reg.predict(x_future)
predictions = ada_pred

valid = cData[X.shape[0]:]
valid['Predictions'] = predictions
plt.figure(figsize=(16,8))
plt.title("Gradient Boosting Regression Model")
plt.xlabel("Days")
plt.ylabel("Close Price (Rs.)")
plt.plot(cData['Close'])
plt.plot(valid[['Close','Predictions']])
plt.legend(['Original','Value','Prediction'])
mae_ada = mean_absolute_error(valid['Close'], predictions)
mape_ada = mean_absolute_percentage_error(valid['Close'], predictions)
mse_ada = mean_squared_error(valid['Close'], predictions)
r2_ada =  r2_score(valid['Close'], predictions)
print("R_Squared = ",r2_ada)
print("MSE = ",mse_ada)
print("MAPE = ",mape_ada)
print("MAE = ",mae_ada)
plt.show()

"""Metrices Matrix"""

# pip install tabulate

from tabulate import tabulate

table = [['Model Name', 'R2 score', 'MSE','MAPE','MAE'], 
         ['Linear Regression', r2_lr, mse_lr,mape_lr,mae_lr],
         ['Decision Tree', r2_tree, mse_tree,mape_tree,mae_tree],
         ['Random Forest', r2_rf, mse_rf,mape_rf,mae_rf],
         ['SVR', r2_svr, mse_svr,mape_svr,mae_svr],
         ['LSTM', r2_lstm, mse_lstm,mape_lstm,mae_lstm],
         ['Lasso', r2_lasso, mse_lasso,mape_lasso,mae_lasso],
         ['KNN ', r2_knn, mse_knn,mape_knn,mae_knn],
         ['Bayesian Ridge', r2_bar, mse_bar,mape_bar,mae_bar],
         ['Gradient Boosting', r2_gbr, mse_gbr,mape_gbr,mae_gbr],
         ['Ada Boost', r2_ada, mse_ada,mape_ada,mae_ada],
         
         ]

print(tabulate(table, headers='firstrow', tablefmt='fancy_grid',showindex=range(1,11)))

"""Negative R² can be,
1. Model is not learning the trend that is present in the train data.
2. Too little data has been used to evaluate the model compared to train data.
3. Too many outliers are present in the dataset.
"""